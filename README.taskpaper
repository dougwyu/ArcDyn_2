- This file records notes about what i have done with the ArcDyn files, and also lists to dos
ArcDyn paper recode 2019:
	- redownload the files from Amazon S3 @done(2019-01-14)
		- create repo @done(2019-01-13)
		- start restore process @done(2019-01-13)
		- re-org the sequence data to prep for upload to datadryad:  create a single folder holding all sequence files.  @done(2019-01-12)
		- download from S3 @done(2019-01-13)
	- combine fastq files @done(2019-01-14)
		- run fastq_combine to concatenate fastq.gz files within the same sample.  large fastq files are broken into multiple fastq files and into multiple folders @done(2019-01-14)
		- PlatesA2B2 @done(2019-01-14)
			- (I think) i fixed a bug here and now include files that had been in PKG-ENQ-1643-Data_Transfer-PSEQ-1657_1_lanes/ but not included before because the folder name previously was PKG-ENQ-1643-Data_Transfer-PSEQ-1657_1_lane/ and my pathname was PKG*lanes/  I have 171 files now, instead of the previous 168. @flag @done(2019-01-20)
			- I have 171 wells @done(2019-01-14)
		- PlatesAB @done(2019-01-14)
		- PlatesEF @done(2019-01-14)
		- PlatesGH @done(2019-01-14)
	- trimgalore @done(2019-01-15)
		- rm the original fastq.gz files, leaving only the post-trimmed fq.gz files @done(2019-01-15)
	- fastqc and multiqc @done(2019-01-15)
	- minimap and samtools @done(2019-01-19)
		- minimap2 and samtools against 308 mitogenomes @done(2019-01-16)
		- download minimap2_output 308mitogenome files @done(2019-01-16)
		- minimap and samtools against 406 COI barcodes @done(2019-01-19)
		- download minimap2_output 406barcode files @done(2019-01-19)
		- AFTER downloading the files, add a line to remove minimap2_outputs/ folders in all BWA folders.  This can be added to the launch_postsamtools_copy_idx_genomecov_files.sh file @done(2019-01-20)
	- idxstats and genomecov tabulate @done(2019-01-20)
		- i fixed a bug here. i previously set coverage = col_double() in the loadFile2() function, but this choked on very high coverage numbers (written by bedtools genomecov in scientific notation (e.g. 1.02553e+06 instead of 1025530).  i have commented out the col_types() part of the function, and read_tsv() parses column types by itself (turns out that col_double() can read sci notation). I no longer get that parsing error when importing. The bug was causing some of the COI spike PctCoverage numbers to be NA because some of the positions had very deep coverage. Now, we get the expected 100% input.  @flag @done(2019-01-20)
		- The effect of this bubble is to set the very high-coverage positions in some barcodes or mitogenomes to NA. So when Percent Coverage is calculated in the same input function (loadFile2), the numerator and denominator values (positions withcoverage > 1) / (length of mitogenome) are both smaller by a few positions. This basically had no effect on PC values, especially since any reference sequence that has some positions with more than 1 million coverage is a reference sequence that has 100% percent coverage. @done(2019-01-20)
	- env analyses are fine @flag @done(2019-01-20)
		- the DY and OO env_COI datasets are identical except for 1 sample (Date_2011_07_22_TrapC_A2B2), which was added in the new dataset (adds 6 lines:  3 detected species and the 3 coi spikes for that sample) @done(2019-01-20)
		- the DY and OO env_mitogenome datasets are also identical except for at least 2 (3?) samples, which were added in the new dataset (adds 67 lines) @done(2019-01-20)
		- ran Step_5.2_environmental_analysis.r, and the two Figure 1s are almost exactly the same (tiny diffs due to a few more data points in the new dataset. @done(2019-01-20)
		- So this part is fine. @flag @done(2019-01-20)
	- mock analyses are fine @flag @done(2019-01-20)
		- i fixed the numbering of the replicates in PlateF_ME100_1/2. The replicate numbers had been reversed (1 was 2;  2 was 1). This probably had no effect, but it allows easier dataset comparisons. @done(2019-01-20)
		- I change the experiment name from negativecontrol to negctrl to make it look like the previous dataset @done(2019-01-20)
		- I fixed the inputDNA amounts for the mockgradient species. The incorrect table assigned the wrong inputDNA values to the more abundant species (mostly just amongst the high-input-value species. This is why the inputDNA~FSL scatterplot had errors only in the upper right hand corner (high FSL, high inputDNA). @done(2019-01-20)
		- Now the new mock dataset looks exactly like the mock dataset used by Otso for the original analyses. @done(2019-01-20)
	- rewrite 1,2,3,4_idxstats_tabulate_macOS_PlatesA2B2.Rmd and 7_datafiles_for_ArcDyn_methods.Rmd to output input_data_step5_20190120.RData for Otso's Step 5.1 code (there are 10 files) @flag @done(2019-01-24)
		- create column to allow removal of these in the env_data files:  c("Sarcoptiformes", "Trombidiformes", "Entomobryomorpha", "Neelipleona", "Poduromorpha", "Symphypleona") @done(2019-01-24)
	- # CHECK THESE ISSUES:  @done(2019-01-24)
		- This is correct: H12 is a buffer blank, and C2 did not generate sequence data. "The sequencing of plates G and H for quotation HEL.TR.ENQ-2379.B.01 has now been completed and a summary of the raw data is attached.  Please note that your sample references have been taken from the attached sample information form (SIF), assuming that samples S1 – S96 are Plate G and S97 onwards (well “A13”) are plate H.   There are 2 samples in Plate H which didn’t generate reads, from wells C2 and H12; according to the SIF, Plate H well H12 (sample S192) contains a blank. " @done(2019-01-24)
		- "find the origin of the single 1998 sample that is out of sequence in Table S4.2."  This sample was originally written as in the metadata sheet as "1998Jul28_Art3_TrapA_wk31", but there are no Jul28 samples, only Jul29 samples. So i changed to 1998Jul29_Art3_TrapA_Wk31. In Plates EF, there are 5 total samples that are technical replicates (2 from 1998, 1 from 1999, and 2 from 2013). I have fixed Table S4.2 to reflect this  @flag @done(2019-01-24)
			- I have fixed Table S4.2. There are two samples that failed to get sequenced in their original runs but did get sequenced in a subsequent run. by default, these are originals, and the total number of unique environmental samples is now 492. @done(2019-01-24)
		- run the tutorial pipeline on macOS.  If it works, then send to Otso.
	- Management tasks after running the pipeline
		- create a new repo with the new code, which can be published on github
		- make README files for each RUN, describing the origins of the sequence files and what i did to them
		- after i run whole pipeline, remove these folders and files
			- original archived files on HPC that i downloaded from Amazon Glacier:  ~/ArcDyn/Amazon_archive_files_to_rm_at_end @done(2019-01-24)
			- the redundant folder on S3:  amazon-working-douglasyu/Earlham_soups_20160910/ 
		- update content of:  amazon-working-douglasyu/readme_Amazon_glacier_file_descriptions_20180128 (explain that PlatesEF contains four PSEQ folders, with 'Plate' as the prefix)
		- make subfolders in Amazon-glacier and organise files in there
		- ask Yinqiu to delete unneeded files from her folder
		- start uploading fastq files to SRA
			- Plates IJCD
			- Plates A2B2, AB, EF, GH
Archived To Dos that i should add to above:
	- go over code in fine detail and see if i can find any bugs:  especially in the table joining steps
	- list which samples produced very little or no data, check against the library QC information, and see if any are legitimately missing or i can ask EI to resupply
		- Darren has sent me library QC information for GH.  look up A2B2, EF:  
			- LITE update G & H 20171023.rtfd
					- Plate G 
						A12
						B03
						F07
						F10
						D10
						B10
						E10
						B08
					- Plate H  
						C08
						B08
						F01
						G03
						G09
						C07
						G06
						C05
						B07
						D05
						H12
						G01
						C02
						B04
	- bwa against mitogenomes and barcodes and compare
		- http://homer.ucsd.edu/homer/basicTutorial/mapping.html
		- bwa index -a bwtsw genome.fa # build index.  What is bwtsw?
		- bwa mem -t $NPROC genome.fa reads1.fq reads2.fq | samtools view -F 0x4 -b | samtools sort > aln-pe.bam # 
		- samtools depth -a instead of bedtools genomecov -d
	- Pardosa glacialis missing from mock samples.  WHY?  @flag @done(2019-01-13)
		- extract Pardosa-mapped reads from a bam file (htsbox bam2fq?)  that has lots of Pardosa in it and use those to map against the mock samples @done(2019-01-13)
	- ArcDyn:  genes and primers for the non-mitogenome species @flag @done(2019-01-12)
	- make textfile for taxonomy (class, order, family, genus, species) of each mitogenome and join to idx_meta_genomecov @done(2019-01-12)
Records:
	- A2B2 missing files
		- situation as of 20180219
			- I think that 16 samples are still running on lane 11
			- 8 samples produced no data but were included in the already-run 10 lanes and thus produced no fastq files
			- 168 samples successfully produced at least some data
			- 16+9+168 = 192 samples
			- of the 168 samples, 15 of the samples produced such little data that they are being omitted at the R stage
			- of the 24 samples that produced zero (n=8) or little (n=16) data, it might be the case the PlatesAB produced data for those samples. This appears to be the list of omitted samples
				[1] "1997AUG20_Art3_TrapA_Wk34" "1997JUL08_Art3_TrapA_Wk28" "2011JUL14_Art3_TrapC_Wk28" "2012AUG19_Art3_TrapA_Wk33"
				[5] "2013AUG26_Art3_TrapA_Wk35" "2013JUL09_Art3_TrapB_Wk28" "1997AUG05_Art3_TrapC_Wk32" "2013AUG26_Art3_TrapB_Wk35"
				[9] "1998JUL29_Art3_TrapC_Wk31" "1999AUG26_Art3_TrapA_Wk34" "2011JUL08_Art3_TrapB_Wk27" "2011JUL22_Art3_TrapC_Wk29"
				[13] "2011AUG25_Art3_TrapA_Wk34" "1999JUL29_Art3_TrapC_Wk30" "2011JUL01_Art3_TrapA_Wk26" "2013JUN17_Art3_TrapB_Wk25"
				[17] "2012SEP02_Art3_TrapB_Wk35" "2011AUG16_Art3_TrapA_Wk33" "2011AUG06_Art3_TrapC_Wk31" "2011AUG06_Art3_TrapB_Wk31"
				[21] "2013JUL22_Art3_TrapC_Wk30" "2012AUG19_Art3_TrapB_Wk33" "2013JUL29_Art3_TrapC_Wk31" "1997JUL08_Art3_TrapC_Wk28"
			- information analysed in:  2017/bulk_samples/platesA2B2/ENQ-1643_PIP-1744_PSEQ-1600_and_PSEQ-1618_datasum_23.01.18.xlsx
	- check number of samples in A2B2;  should be 168.  
		- outcome:  yes.  i downloaded 168 sets of fastq files.  
	- convert some bam files to paf format to look at distribution of mapping qualities (https://github.com/lh3/htsbox):  htsbox samview -p in.bam > out.paf.
		- https://github.com/lh3/miniasm/blob/master/PAF.md # for PAF format
		- outcome:  60 is indeed the max value, and looking at the histogram of mapping values, i have decided to re-run with -q 48
	- view the bam files:  mapping to NNNNN's??  
		- outcome:  this is known as hard masking, and BWA does not map to these parts.  minimap2 also appears to avoid them in the counting of the alignment 
	- samtools view -F 0x4 removes UNMAP reads, which reduces the file sizes to 1% of main bam. Thus, samtools filter -F 0x4 the minimap2 outputs
		- outcome:  re-running minimap2 to reduce size of files. filtered through minimap2_COIBarcodes only sam files to remove unmapped. These unmapped reads are just a copy of the reads in the fq files
	- run R code on AB, A2B2, GH, and EF and compare with Yinqiu's results and also the COI spike and the positive controls
		- write R code to process the samtools outputs:  idxstats_tabulate
			-  Read in all idx_stats files, add sample metadata to columns, and merge into one table in long format (vertically by time)
			-  merge with sample excel workbook to add the sample date information
			-  go through the genomecov files and calculate the mean and standard deviation of coverage for each mitogenome/sample and add the columns to the idx table
			-  make wide table using tidyr (the column data format should be DateTrap (e.g. 1998_08_05_TrapA) in temporal order).
			-  confirm that i have the correct number of samples (compare with number of input files) e.g. PlatesAB only have 176 bam files (answer:  i only initially downloaded 176 bam files for code testing)
			-  Debug the bug that causes sample to have repeated lines, using a tabulate command to check that I don't have repeated lines.  Answer: re-run the minimap2/samtools/bedtools scripts and redownload the idxstats files.  iit wasn't a bug.  I had put the same idxstats files into multiple BWA folders in my test folders
			-  create lysis buffer datasets, download idxstats and genomecov data, run R code on Plates AB, A2B2, EF, GH
		-  platesGH:  combine_fastq, fastQC, multiqc (using PKG-ENQ-2379-Data_Transfer-PSEQ-1586-trimmed), remove orig fastq.gz files.  
		- remove original, noncombined fastq.gz files from A2B2 and GH when i'm done mapping and checking.
		-  platesA2B2: combine_fastq, fastQC, multiqc, remove orig fastq.gz files
		-  minimap2/samtools for platesGH
		-  minimap2/samtools for platesA2B2
		- download samtools outputs for minimap2 to mitogenomes for q60 (F2308_f0x2_q60)
		- finish running minimap2 and samtools scripts:  download PlatesEF samtools outputs for minimap2 to barcode COIs
		- save folders with the bamfiles and samtools outputs for minimap2 to barcode COIs
		- Compare PlatesAB and A2B2 WITH YINQIU'S BWA_results_20161025.xlsx.  
		- Compare PlatesGH, PlatesEF with the positive controls, the seasonal patterns, the COI spikes
		- analyse minimap2 against mitogenomes for F2308 f0x2 q60
		- analyse minimap2 against barcodes_only for F2308, q1 and q60
		- re-run minimap2 against mitogenomes to re-generate the bam files?  benefit is that i can then run further samtools at any time. cost is storage space
		- outcome:  i have successfully produced output files for Otso.  now the job is to refine and solve the pardosa problem
		- visualise minimap2 bam files and check that i am not mapping to the Ns between the protein-coding genes. SHOULD I SUBTRACT A FIXED NUMBER FROM EACH MITOGENOME LENGTH TO CALCULATE THE CORRECT LENGTH OF THE CODING PORTION?  
	- re run minimap2/samtools/bedtools/R pipeline with F2308 q48 and compare with F2308 q60
		- q48 produces maybe 5-10% more reads and correspondingly more reads for false positives (although the Coef vars for false positives are still high). There is not much benefit nor much cost to using q48.  note that I did not filter for PROPER PAIRS, which should reduce the false positives
	- run PlatesGH against 19 positive control species and look at the mocks (20180223)
		- all 19 species detected except for Pardosa glacialis
		- within species ratios are accurate
		- across species gradient is roughly accurate
		- CVs are low (below 1.5)
		- upshot:  we can detect even low biomass fraction species (although in this run, i did not map against other mitogenomes so did not test directly for false positives)
	- 20180223: re-run PlatesA2B2, adding the final Lane 11
		- added the final fastq files (after the trimming step)
		- re-mapped and samtools filtered.  these output files are now the new output files
		- Lanes 1-11 all have all the samples, so adding Lane 11 did not increase number of samples but did increase by around 10% the amount of sequence data compared to the Lanes 1-10 only run
	- 20180227: run pipeline against new mitogenome reference database containing 307 species
	- 20180228: send 307 mitogenomes to Tea, annotated, so they include any 16S and 12S genes assembled
	- 20180301: download B2 files and upload to S3 Glacier for long-term storage